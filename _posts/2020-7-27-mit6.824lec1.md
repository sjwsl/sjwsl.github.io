---
# layout: post
title: MIT 6.824 Lecture 1
categories: 
    - Lecture Notes
tag:
    - 6.824
    - Distributed Systems
    - MapReduce
---

Introduction

## 分布式系统

分布式系统的本质是让多台物理隔离的计算机通过网络来协调，共同完成一致任务。

如果我们能在一台计算机上解决问题，那就不应该使用分布式系统，因为这会让问题变复杂。

### 分布式系统的优势

- 更高的性能（并行）
- 容错（fault tolerate）
- 使计算在物理上接近他的外部实体（例如银行的服务器自然地应该在本地，而不同地区的服务器需要协同工作）
- 安全（通过隔离 isolation）

这门课程主要关注的是性能和容错

### 分布式系统的挑战

- 并发本身带来的问题（data race）
- 故障：各个计算机和网络都有可能出现局部故障
- 性能：实际上很难通过并行达到预期的性能提升

## 关于 6.824

### Lab

1. MapReduce

2. Raft

3. 基于 Raft 实现一个 fault-tolerate 的分布式 KV server

4. shared KV server

### 主题

这是一门关于基础架构的课程，基础架构分为三种
- 存储
- 通信
- 计算

我们主要关注的是存储，构建一种多副本、容错的、高性能分布式存储实现。

我们还会讨论一些计算系统，比如 MapReduce。

Big Goal: 设计一系列接口，对应用隐藏所有关于分布式系统的细节，从而可以像普通系统一样使用（事实上这是很难实现的）

接下来分别讨论我们会面对的各种主题

#### 实现

- RPC
- 线程
- 并发控制

#### 性能

通常来说，构建分布式系统的目的是为了获得可扩展的加速

Nx servers -> Nx total throughput via parallel CPU, disk, net.

系统的**可扩展性（scalability）**意味着我们只需要增加计算机的数量，就可以获得更好的性能，而不用重新设计系统。

随着计算机数量增长，可扩展性面临着很多挑战
- 负载不平衡
- 最慢的计算机决定系统的总处理时间（木桶原理）
- 天然不可并行的代码：初始化、交互
- 共享资源的瓶颈：数据库、网络
- 一些性能问题无法通过简单地增加计算机解决
  - 提高单个请求的响应时间
  - 所有用户更新相同的数据（data race）

因此我们需要更好的设计

#### 容错

如果只有一台计算机，系统大多时候是可靠的。然而如果我们数千台计算机，故障应该被当作不断发生的问题来处理。

系统的**可用性（availability）**意味着在特定的错误类型下，系统仍然能够正常运行，仍然可以像没有出现错误一样，提供完整的服务。

然而有时候系统不可能正常运行（比如所有计算机同时故障），这时我们可以允许系统不再响应请求，但不能返回错误的结果。

系统的**可恢复性（recoverability）**是一个比可用性更弱的需求。这意味着当致命的错误出现，系统会停止工作，但是修复之后又可以完全正常运行。

最重要的工具：
- 非易失存储 non-volatile storage
- 复制 replication

#### 一致性

系统的**一致性（consistency）**要求每个操作的行为都是良好定义的。

考虑一个 KV 系统，支持两种操作
- Put(K,V): 把 K 的值设为 V
- Get(K): 获取 K 的值

对于单一计算机的系统，这两个操作的定义都是显然的。系统存储一个表单，Put 更新表单中的某一项，Get 获取表单中某一项。然而在本不是系统中，由于复制和缓存（当然普通系统中也有缓存），会有多个版本的表单。当有错误发生时，不同表单可能会不一致，这时我们就需要定义 Put/Get 操作的规则。

**强一致性（strong consistency）**保证 Get 会得到最近一次 Put 写入的值。这看起来很显然，然而事实上这在分布式系统中是很难做到的，或者说实现的代价非常高。几乎可以确定的是，分布式系统的各个组件需要做大量的通信，才能实现强一致性。而分布式系统中的计算机可能分布在世界的两端，用于维护强一致性就需要难以接受的通信代价。

因此人们通常使用**弱一致性（weak consistency）**的系统，它并不保证 Get 会得到最近一次 Put 写入的值。虽然这对使用者来说很痛苦，但的确是为了速度的无奈之举。当然，为了让弱一致性更有意义，系统会定义其他的规则。

## MapReduce

MapReduce 是一个很好的案例，它体现了之前提到的大部分主题。

### 背景

Google 面临的问题是在 TB 级的数据上做小时级的运算。比如，为所有网页创建索引，分析网页的结构。他们需要一种框架，使得不熟悉分布式系统的普通工程师也可以很容易的完成并运行大规模的分布式运算。这就是MapReduce出现的背景。

MapReduce 的思想是，使用者只需要写 Map 函数和 Reduce 函数，MapReduce 框架会处理剩下的事情。

### 过程

假设输入已经被分为 M 个文件，MapReduce 对每个文件运行 Map 函数。Map 的函数是 key-value 对的列表，存储为中间结果。之后每个 Reduce 函数会收集所有相同 key 的 key-value 对，输出结果。

例如，单词统计的 Map 函数和Reduce 函数可以定义如下
```
Map(filename, file)
    for word in file
        emit(word, "")
Reduce(k, v)
    emit(len(v))
```

MapReduce 要求 Map 和 Reduce 函数都是无状态的，这样两个阶段都可以获得理想的并行加速效果。

最初，MapReduce 的瓶颈在于网络。因为 Map 后的数据是按行存储的，而 Reduce 需要的是按列存储的数据。所以每个 Reduce 函数可能都要从所有的 Map 节点通过网络获取所需的数据（论文中称为 shuffle），这是 MapReduce 中消耗较大的一部分。